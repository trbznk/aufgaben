{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SPLITTING UND PYTORCH DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1\n",
    "\n",
    "Splitte die Daten `data` in `train_data` und `test_data` auf.\n",
    "- Verhältnis von 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Längere Überlegung und Versuche: SKLearn-Data-Split will einen numpy-dataframe übergeben bekommen!\n",
    "# Diesen muss ich also aus den Daten bilden! die Form der Daten passt (zweidimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83267073, 0.74702149, 0.56914635, 0.8411728 , 0.69645239],\n",
       "       [0.82611318, 0.63207124, 0.9165846 , 0.92089508, 0.67136711],\n",
       "       [0.30808429, 0.24690685, 0.92392668, 0.79440508, 0.51804712],\n",
       "       ...,\n",
       "       [0.75294363, 0.70357942, 0.19790992, 0.53776532, 0.26666421],\n",
       "       [0.7206661 , 0.35189566, 0.79396687, 0.79029605, 0.79262557],\n",
       "       [0.22987563, 0.07776973, 0.41260077, 0.31012527, 0.61439593]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.832671</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.569146</td>\n",
       "      <td>0.841173</td>\n",
       "      <td>0.696452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.826113</td>\n",
       "      <td>0.632071</td>\n",
       "      <td>0.916585</td>\n",
       "      <td>0.920895</td>\n",
       "      <td>0.671367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.308084</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>0.923927</td>\n",
       "      <td>0.794405</td>\n",
       "      <td>0.518047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.968414</td>\n",
       "      <td>0.467990</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.163620</td>\n",
       "      <td>0.174387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401210</td>\n",
       "      <td>0.589401</td>\n",
       "      <td>0.869008</td>\n",
       "      <td>0.329988</td>\n",
       "      <td>0.562295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.043316</td>\n",
       "      <td>0.432197</td>\n",
       "      <td>0.240033</td>\n",
       "      <td>0.461701</td>\n",
       "      <td>0.116707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.776171</td>\n",
       "      <td>0.172867</td>\n",
       "      <td>0.794609</td>\n",
       "      <td>0.013288</td>\n",
       "      <td>0.370132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.752944</td>\n",
       "      <td>0.703579</td>\n",
       "      <td>0.197910</td>\n",
       "      <td>0.537765</td>\n",
       "      <td>0.266664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.720666</td>\n",
       "      <td>0.351896</td>\n",
       "      <td>0.793967</td>\n",
       "      <td>0.790296</td>\n",
       "      <td>0.792626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.229876</td>\n",
       "      <td>0.077770</td>\n",
       "      <td>0.412601</td>\n",
       "      <td>0.310125</td>\n",
       "      <td>0.614396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4\n",
       "0    0.832671  0.747021  0.569146  0.841173  0.696452\n",
       "1    0.826113  0.632071  0.916585  0.920895  0.671367\n",
       "2    0.308084  0.246907  0.923927  0.794405  0.518047\n",
       "3    0.968414  0.467990  0.002175  0.163620  0.174387\n",
       "4    0.401210  0.589401  0.869008  0.329988  0.562295\n",
       "..        ...       ...       ...       ...       ...\n",
       "995  0.043316  0.432197  0.240033  0.461701  0.116707\n",
       "996  0.776171  0.172867  0.794609  0.013288  0.370132\n",
       "997  0.752944  0.703579  0.197910  0.537765  0.266664\n",
       "998  0.720666  0.351896  0.793967  0.790296  0.792626\n",
       "999  0.229876  0.077770  0.412601  0.310125  0.614396\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data)# aud den zweidim Numpy Daten einen Dataframe bilden, um SKLeanr Split machen zu können !\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nun kann ich über den Parameter test_size=0.30 df übergeben und 30% Testdaten absplitten, es bleiben 70% Traindaten\n",
    "# In diesem zusammenhang noch unklar: was genau tut der Parameter random_state=042? Klären wir später?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            0         1         2         3         4\n",
       " 541  0.876108  0.480591  0.229952  0.706183  0.750458\n",
       " 440  0.881301  0.217575  0.759872  0.699913  0.175919\n",
       " 482  0.742994  0.496818  0.587285  0.509254  0.716307\n",
       " 422  0.916896  0.691851  0.065028  0.290177  0.688857\n",
       " 778  0.531375  0.592227  0.046583  0.098956  0.033163\n",
       " ..        ...       ...       ...       ...       ...\n",
       " 106  0.706368  0.857731  0.871006  0.557343  0.145602\n",
       " 270  0.590260  0.969887  0.760600  0.649741  0.576860\n",
       " 860  0.864413  0.321628  0.367762  0.723900  0.086900\n",
       " 435  0.791348  0.043786  0.795547  0.039074  0.391639\n",
       " 102  0.587775  0.062448  0.691947  0.796169  0.100470\n",
       " \n",
       " [700 rows x 5 columns],\n",
       "             0         1         2         3         4\n",
       " 521  0.321380  0.394971  0.099972  0.804085  0.165798\n",
       " 737  0.210410  0.203165  0.389690  0.586870  0.625863\n",
       " 740  0.366983  0.861400  0.229307  0.378569  0.547450\n",
       " 660  0.956691  0.697334  0.209201  0.532947  0.228746\n",
       " 411  0.276785  0.790399  0.415504  0.110745  0.274715\n",
       " ..        ...       ...       ...       ...       ...\n",
       " 468  0.190416  0.328304  0.733558  0.027794  0.930050\n",
       " 935  0.113641  0.531909  0.292347  0.935176  0.149431\n",
       " 428  0.898845  0.723721  0.326875  0.584403  0.085972\n",
       " 7    0.345736  0.851093  0.210414  0.006023  0.606519\n",
       " 155  0.433313  0.915739  0.411455  0.143043  0.410420\n",
       " \n",
       " [300 rows x 5 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.30, random_state=42)\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 5), (300, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alles richtig\n",
    "# alternativ einfach ohne Umweg über pandas\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.3)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2\n",
    "\n",
    "Splitte die Daten `x` und `y` in `x_train`, `x_test`, `y_train` und `y_test` auf.\n",
    "- Verhältnis 95%/5%\n",
    "- Daten sollen beim Split nicht zufällig gemischt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.10961867, 0.04824369, 0.41961594, 0.98184486, 0.05522578],\n",
       "        [0.23831179, 0.2528238 , 0.72407389, 0.43389106, 0.53625981],\n",
       "        [0.29395471, 0.57237927, 0.12469123, 0.29472794, 0.96122662],\n",
       "        ...,\n",
       "        [0.9210045 , 0.71687428, 0.56026608, 0.14456795, 0.673488  ],\n",
       "        [0.19350292, 0.52441029, 0.14986502, 0.80393684, 0.0983729 ],\n",
       "        [0.23893161, 0.76223892, 0.66975992, 0.05810729, 0.58145148]]),\n",
       " array([1, 0, 1, ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(10000, 5)\n",
    "y = np.random.rand(10000).round().astype(int)\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten sollen beim Split nicht zufällig gemischt werden => meines Erachtens Random_state=None !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9500, 5), (500, 5))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = train_test_split(x, test_size=0.05, random_state=42) # direkter Versuch, da x in passender Ausgangsshape vorliegt\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9500,), (500,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = train_test_split(y, test_size=0.05, random_state=42) # direkter Versuch, da x in passender Ausgangsshape vorliegt\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nun die randomisierung rausnehmen => shuffle=False, stratify=None Schwer zu überprüfen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9500, 5), (500, 5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = train_test_split(x, test_size=0.05,  shuffle=False, stratify=None)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9500,), (500,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = train_test_split(y, test_size=0.05, shuffle=False, stratify=None)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9500, 5), (500, 5), (9500,), (500,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# am Ende richtig\n",
    "# alternativ und kürzer\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05, shuffle=False)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3\n",
    "\n",
    "Splitte die Daten `data` in `train`, `dev` und `test` auf.\n",
    "- Verhältnis 60%/20%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11871409, 0.84089466, 0.09315831, 0.98052607, 0.91949041],\n",
       "       [0.0864952 , 0.52936228, 0.61240211, 0.18032874, 0.19336573],\n",
       "       [0.93368526, 0.02171262, 0.82014709, 0.3231843 , 0.74629226],\n",
       "       ...,\n",
       "       [0.93216163, 0.26255706, 0.2191875 , 0.48658815, 0.27021084],\n",
       "       [0.39182445, 0.1563037 , 0.88776811, 0.11036809, 0.10580978],\n",
       "       [0.52234142, 0.14266026, 0.62678278, 0.42322476, 0.7049603 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.rand(1000, 5)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir bilden zunächst wieder einen pandas dataframe aus den Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030979</td>\n",
       "      <td>0.453657</td>\n",
       "      <td>0.561658</td>\n",
       "      <td>0.443964</td>\n",
       "      <td>0.985562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350198</td>\n",
       "      <td>0.957822</td>\n",
       "      <td>0.338817</td>\n",
       "      <td>0.491040</td>\n",
       "      <td>0.933789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.675748</td>\n",
       "      <td>0.022404</td>\n",
       "      <td>0.747185</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.346253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085321</td>\n",
       "      <td>0.382406</td>\n",
       "      <td>0.846828</td>\n",
       "      <td>0.216170</td>\n",
       "      <td>0.825235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.710898</td>\n",
       "      <td>0.965902</td>\n",
       "      <td>0.698475</td>\n",
       "      <td>0.198980</td>\n",
       "      <td>0.937054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.998585</td>\n",
       "      <td>0.290623</td>\n",
       "      <td>0.231042</td>\n",
       "      <td>0.183385</td>\n",
       "      <td>0.992052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.648724</td>\n",
       "      <td>0.970172</td>\n",
       "      <td>0.364782</td>\n",
       "      <td>0.870509</td>\n",
       "      <td>0.882351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.631017</td>\n",
       "      <td>0.538946</td>\n",
       "      <td>0.936068</td>\n",
       "      <td>0.966754</td>\n",
       "      <td>0.290096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.794143</td>\n",
       "      <td>0.814143</td>\n",
       "      <td>0.240370</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.805828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.696080</td>\n",
       "      <td>0.912125</td>\n",
       "      <td>0.692208</td>\n",
       "      <td>0.169917</td>\n",
       "      <td>0.491824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4\n",
       "0    0.030979  0.453657  0.561658  0.443964  0.985562\n",
       "1    0.350198  0.957822  0.338817  0.491040  0.933789\n",
       "2    0.675748  0.022404  0.747185  0.999391  0.346253\n",
       "3    0.085321  0.382406  0.846828  0.216170  0.825235\n",
       "4    0.710898  0.965902  0.698475  0.198980  0.937054\n",
       "..        ...       ...       ...       ...       ...\n",
       "995  0.998585  0.290623  0.231042  0.183385  0.992052\n",
       "996  0.648724  0.970172  0.364782  0.870509  0.882351\n",
       "997  0.631017  0.538946  0.936068  0.966754  0.290096\n",
       "998  0.794143  0.814143  0.240370  0.329200  0.805828\n",
       "999  0.696080  0.912125  0.692208  0.169917  0.491824\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data)# aud den zweidim Numpy Daten einen Dataframe bilden, um SKLeanr Split machen zu können !\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorgehen: zuerst einen train-test Split, dann einen train-dev Split !\n",
    "# ein wenig trickie ist, erst df einzusetzen und dann train - sollte aber stimmen! (?)\n",
    "# Geht sicher noch anders oder auf elefanterem Wege?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 5), (200, 5))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.20, random_state=42) # Split für test set, 20 ab von df!\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 5), (200, 5))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, dev = train_test_split(train, test_size=0.25, random_state=42) # dev für validation set, 25& ab von train!\n",
    "train.shape, dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 5), (200, 5), (200, 5))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# richtig\n",
    "# alternative kürzer ohne Umweg mit pandas\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train, dev = train_test_split(train, test_size=0.25)\n",
    "train.shape, dev.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4\n",
    "\n",
    "Wir haben ein `Dataset` erzeugt. Jedoch gibt es bei `len(data)` nicht die richtige Länge (Anzahl der Elemente) zurück.\n",
    "Behebe den Fehler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(10000, 5)\n",
    "y = np.random.rand(10000).round().astype(int)\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        x = len(self.x)\n",
    "        y = len(self.y)\n",
    "        return x\n",
    "        return y\n",
    "     \n",
    "    \n",
    "    \n",
    "data = Data(x, y)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lange rumgetestet: so müsste ich die Länge von x und y ausgeben, die 5 ergeben sich ja nur in der Shape von x - länge ist immer 1000 bei x und y!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# richtig auch wenn das zweite return raus muss\n",
    "# wir können davon ausgehen, dass x und y die gleich länge haben\n",
    "\n",
    "x = np.random.rand(10000, 5)\n",
    "y = np.random.rand(10000).round().astype(int)\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "     \n",
    "    \n",
    "    \n",
    "data = Data(x, y)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 5\n",
    "\n",
    "Passe die Methode `__getitem__()` so an, dass sie den `x` und `y` Teil beim gegebenen Index `i` als `tuple` zurückgibt.\n",
    "\n",
    "Beispiel:\n",
    "```python\n",
    "(array([0.45740839, 0.28119272, 0.5612359 , 0.78179437, 0.07652732]), 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ein Tupel ist in einem Dict zuhause, oder? also in {} packen. Unsinn! Ich muss es aus der Poll prediction holen, dort was mit formatstring gemacht ! Tupel einfach so bilden als Paarwerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im Wesentlichen eine Problem zur Lösung der Fehlermeldung \"'numpy.ndarray' object has no attribute iloc\"\n",
    "# Konvertieren in einen Pandas Dataframe, dann die gelernte Vorgehensweise - es sollte ein Tupel sein, welches herauskommt!\n",
    "# Mir ist unklar, wieso der data rot einfärbt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1884, 0.2731, 0.2837, 0.4419, 0.2146]), tensor([1.]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(10000, 5)\n",
    "y = np.random.rand(10000).round().astype(int)\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = pd.DataFrame(x)\n",
    "        self.y = pd.DataFrame(y)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.x.iloc[i]).float(), torch.tensor(self.y.iloc[i]).float()\n",
    " \n",
    "\n",
    "data = Data(x, y)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-26b41d641f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-26b41d641f64>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# das hier geht dann eben nicht!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(10000, 5)\n",
    "y = np.random.rand(10000).round().astype(int)\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = pd.DataFrame(x)\n",
    "        self.y = pd.DataFrame(y)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return np.array(self.x.iloc[i]).float(), np.array(self.y.iloc[i]).float() # das hier geht dann eben nicht!\n",
    " \n",
    "\n",
    "data = Data(x, y)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.08309881, 0.88687148, 0.11696594, 0.92359172, 0.67890401]), 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# falsch ist es nicht\n",
    "# pandas und torch.tensor war nicht gefordert\n",
    "# alternativ und viel kürzer\n",
    "\n",
    "x = np.random.rand(10000, 5)\n",
    "y = np.random.rand(10000).round().astype(int)\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "\n",
    "data = Data(x, y)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
