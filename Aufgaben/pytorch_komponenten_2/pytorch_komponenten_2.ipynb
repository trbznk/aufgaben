{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1\n",
    "\n",
    "Erzeuge eine Lineare Layer welche $12$ *inputs* aufnimmt und $32$ *outputs* ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2\n",
    "\n",
    "![nn](nn.svg)\n",
    "\n",
    "Erzeuge die 5 Layer aus der Visualisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3\n",
    "\n",
    "*Forwarde* `x` durch die `fc` Komponente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4450, 0.4089, 0.0755, 0.7807, 0.4143, 0.2146, 0.8373, 0.1268, 0.0136,\n",
       "         0.4790, 0.2335, 0.0071, 0.7716, 0.2109, 0.7855, 0.1463],\n",
       "        [0.8696, 0.8227, 0.8106, 0.6446, 0.7850, 0.0047, 0.1836, 0.1032, 0.6831,\n",
       "         0.5614, 0.3404, 0.8955, 0.2905, 0.0101, 0.0693, 0.4827],\n",
       "        [0.2293, 0.8057, 0.9155, 0.2660, 0.7720, 0.4341, 0.5658, 0.2060, 0.1225,\n",
       "         0.6583, 0.8975, 0.3266, 0.2081, 0.4750, 0.5740, 0.1383],\n",
       "        [0.1773, 0.2759, 0.9447, 0.1017, 0.5066, 0.4841, 0.6016, 0.2817, 0.7317,\n",
       "         0.7458, 0.4690, 0.1994, 0.3157, 0.0228, 0.2775, 0.3724]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 16)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=8, out_features=3, bias=True)\n",
       "  (5): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Sequential(\n",
    "    nn.Linear(16, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 3),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4\n",
    "\n",
    "Füge der Klasse das richtige *forwarding* hinzu. Bei dem Beispiel handelt es sich im *binary classification*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=1000, out_features=256, bias=True)\n",
       "  (g1): ReLU()\n",
       "  (l2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (g2): ReLU()\n",
       "  (l3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (g3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(1000, 256)\n",
    "        self.g1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(256, 128)\n",
    "        self.g2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(128, 64)\n",
    "        self.g3 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    \n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7991, 0.6659, 0.8573,  ..., 0.4483, 0.1901, 0.8580],\n",
       "        [0.2952, 0.1638, 0.3493,  ..., 0.7371, 0.4326, 0.6241],\n",
       "        [0.9853, 0.6143, 0.4866,  ..., 0.9416, 0.0266, 0.0820],\n",
       "        ...,\n",
       "        [0.9162, 0.3222, 0.8703,  ..., 0.4794, 0.9734, 0.2324],\n",
       "        [0.5609, 0.8927, 0.1099,  ..., 0.4380, 0.0198, 0.8127],\n",
       "        [0.9113, 0.4609, 0.2739,  ..., 0.2094, 0.9510, 0.3388]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(16, 1000)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7991, 0.6659, 0.8573,  ..., 0.4483, 0.1901, 0.8580],\n",
       "        [0.2952, 0.1638, 0.3493,  ..., 0.7371, 0.4326, 0.6241],\n",
       "        [0.9853, 0.6143, 0.4866,  ..., 0.9416, 0.0266, 0.0820],\n",
       "        ...,\n",
       "        [0.9162, 0.3222, 0.8703,  ..., 0.4794, 0.9734, 0.2324],\n",
       "        [0.5609, 0.8927, 0.1099,  ..., 0.4380, 0.0198, 0.8127],\n",
       "        [0.9113, 0.4609, 0.2739,  ..., 0.2094, 0.9510, 0.3388]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 5\n",
    "\n",
    "Beim folgendenen Modell wurde ein *high variance* Problem festgestellt. Füge $2$ *dropuput layers* an sinnvollen stellen hinzu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "    \n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1958, 0.2737, 0.2721, 0.5563, 0.7919, 0.6845, 0.6496, 0.3550, 0.1769,\n",
       "         0.2647, 0.5320, 0.9852, 0.7190, 0.2371, 0.7541, 0.3621],\n",
       "        [0.9529, 0.0021, 0.3855, 0.1273, 0.8816, 0.1121, 0.8637, 0.3594, 0.8049,\n",
       "         0.3972, 0.0342, 0.2374, 0.7328, 0.6447, 0.3527, 0.6209],\n",
       "        [0.4340, 0.5443, 0.9948, 0.8759, 0.8823, 0.1066, 0.6169, 0.3867, 0.2467,\n",
       "         0.9258, 0.0901, 0.3299, 0.8742, 0.4164, 0.4010, 0.4135],\n",
       "        [0.1367, 0.7854, 0.2037, 0.3269, 0.7447, 0.4235, 0.7355, 0.0015, 0.7985,\n",
       "         0.0970, 0.7527, 0.8798, 0.7116, 0.4390, 0.7374, 0.6481]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 16)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3874],\n",
       "        [0.4765],\n",
       "        [0.3703],\n",
       "        [0.3508]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
