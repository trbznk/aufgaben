{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Komponenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2130, 0.8128, 0.9764, 0.9008, 0.6059, 0.6593, 0.1250, 0.5652])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.rand(8)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel\n",
    "\n",
    "Erzeugen einer linear layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0429], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Linear(8, 1) # 8 features[Input], ein Output !\n",
    "m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1\n",
    "\n",
    "Erzeuge eine linear layer und führe ein forwarding wie im Beispiel durch mit: \n",
    "- in_features=8\n",
    "- out_features=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=8, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module): # Vererbung, daher Quelle in die Klammern\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()# gibt die Superklasse nn.module, außerdem rufen wir den Constuctor dieser Klasse auf!\n",
    "        self.l1 = nn.Linear(8, 16)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)# wir überschreiben x mit dem Ergebnis aus Layer1\n",
    "        return x\n",
    "model = Net() # wir erzeugen ein Objekt der Klasse ! und packen es in eine variable (model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1864, -0.9193, -0.2943,  0.7199, -0.4111,  0.6331,  0.1186,  1.1646,\n",
       "        -0.5898,  0.6508, -0.5831, -0.2813, -0.4347,  0.5954,  0.3560, -0.4958],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# falsch, 1. zu viel 2. nicht geforwarded\n",
    "\n",
    "m = nn.Linear(8, 16)\n",
    "m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2\n",
    "\n",
    "Erzeuge eine ReLU activation function und führe ein forwarding wie im Beispiel durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=8, out_features=16, bias=True)\n",
       "  (g): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module): # Vererbung, daher Quelle in die Klammern\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()# gibt die Superklasse nn.module, außerdem rufen wir den Constuctor dieser Klasse auf!\n",
    "        self.l1 = nn.Linear(8, 16)\n",
    "        self.g = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)# wir überschreiben x mit dem Ergebnis aus Layer1\n",
    "        x = self.g(x) # Pro Layer eine ReLU üblicherweise !\n",
    "        return x\n",
    "    \n",
    "model = Net() # wir erzeugen ein Objekt der Klasse ! und packen es in eine variable (model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2130, 0.8128, 0.9764, 0.9008, 0.6059, 0.6593, 0.1250, 0.5652])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# falsch, 1. zu viel 2. nicht geforwarded\n",
    "\n",
    "m = nn.ReLU()\n",
    "m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3\n",
    "\n",
    "Erzeuge eine Dropout layer und führe ein forwarding wie im Beispiel durch.\n",
    "- propability für den Dropout 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=8, out_features=16, bias=True)\n",
       "  (g): ReLU()\n",
       "  (d): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module): # Vererbung, daher Quelle in die Klammern\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()# gibt die Superklasse nn.module, außerdem rufen wir den Constuctor dieser Klasse auf!\n",
    "        self.l1 = nn.Linear(8, 16)\n",
    "        self.g = nn.ReLU()\n",
    "        self.d = nn.Dropout(p=0.3, inplace=False)# Vermutung, inplace kann man analog der Libary übernehmen oder weglasssen (default value)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)# wir überschreiben x mit dem Ergebnis aus Layer1\n",
    "        x = self.g(x) # Pro Layer eine ReLU üblicherweise !\n",
    "        x = self.d(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "model = Net() # wir erzeugen ein Objekt der Klasse ! und packen es in eine variable (model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3043, 1.1612, 1.3948, 1.2869, 0.0000, 0.9418, 0.1786, 0.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# falsch, 1. zu viel 2. nicht geforwarded\n",
    "\n",
    "m = nn.Dropout(p=0.3)\n",
    "m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4\n",
    "\n",
    "Erzeuge sowohl eine linear layer als auch eine ReLU activation function und forwade durch beide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=8, out_features=16, bias=True)\n",
       "  (l2): Linear(in_features=16, out_features=4, bias=True)\n",
       "  (g): ReLU()\n",
       "  (d): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module): # Vererbung, daher Quelle in die Klammern\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()# gibt die Superklasse nn.module, außerdem rufen wir den Constuctor dieser Klasse auf!\n",
    "        self.l1 = nn.Linear(8, 16)\n",
    "        self.l2 = nn.Linear(16, 4)\n",
    "        self.g = nn.ReLU()\n",
    "        self.d = nn.Dropout(p=0.3, inplace=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)# wir überschreiben x mit dem Ergebnis aus Layer1\n",
    "        x = self.l2(x)\n",
    "        x = self.g(x) # Pro Layer eine ReLU üblicherweise !\n",
    "        x = self.d(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "model = Net() # wir erzeugen ein Objekt der Klasse ! und packen es in eine variable (model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3761, 0.0000, 0.8219, 0.3931, 0.0000, 0.4721, 0.1528, 0.0000,\n",
       "        0.0000, 0.4504, 0.1243, 0.1528, 0.5380, 0.6837, 0.0535],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# falsch, 1. zu viel 2. nicht geforwarded\n",
    "\n",
    "m = nn.Linear(8, 16)\n",
    "g = nn.ReLU()\n",
    "\n",
    "# entweder\n",
    "g(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3761, 0.0000, 0.8219, 0.3931, 0.0000, 0.4721, 0.1528, 0.0000,\n",
       "        0.0000, 0.4504, 0.1243, 0.1528, 0.5380, 0.6837, 0.0535],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oder\n",
    "\n",
    "x_ = m(x)\n",
    "x_ = g(x_)\n",
    "x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 5\n",
    "\n",
    "Erzeugt wurde ein eigenes Module namens `CustomModule`.\n",
    "Passe die `forward` Methode so an, dass dem x die Zahl $2$ addiert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2439, 2.8835, 2.7882, 2.0388, 2.0718, 2.9681, 2.2125, 2.2506])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x+2 # 1.Idee innerhalb der Methode, ERgebnis enthält zumindest immer 2 vor dem Komma! Rest war random, oder?\n",
    "        return x\n",
    "    \n",
    "    \n",
    "m = CustomModule()\n",
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# richtig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
